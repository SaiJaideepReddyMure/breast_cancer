# -*- coding: utf-8 -*-
"""Breast_Cancer_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10FFOyK5XcNDiIQPiqVbgtWROqJQ60nD7
"""

# Get the fastai libraries and other important stuff: https://course.fast.ai/start_colab.html
!curl -s https://course.fast.ai/setup/colab | bash

# Authenticate Colab to use my Google Drive for data storage and retrieval
from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)
root_dir = "/content/gdrive/My Drive/"
base_dir = root_dir + 'BreastCancer'

base_dir

# Commented out IPython magic to ensure Python compatibility.
# Change the working directory
# %cd /content/gdrive/My\ Drive/BreastCancer

# Verify
!pwd

!unzip /content/gdrive/My\ Drive/BreastCancer/IDC_regular_ps50_idx5.zip

!find /content/gdrive/My\ Drive/BreastCancer -maxdepth 1 -type d | wc -l

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext autoreload
# %autoreload 2
# %matplotlib inline

from fastai.vision import *
from fastai.metrics import *

import numpy as np
np.random.seed(7)

import torch
torch.cuda.manual_seed_all(7)

import matplotlib.pyplot as ply
plt.style.use('ggplot')

tfms = get_transforms(do_flip=True, flip_vert=True,
                      max_lighting=0.3, max_warp=0.3, max_rotate=20., max_zoom=0.05)
len(tfms)

"""### Loading the data in mini batches of 128 (48x48)"""

path = '/content/gdrive/My Drive/BreastCancer/'
data = ImageDataBunch.from_folder(path, ds_tfms=tfms, valid_pct=0.2,
                                  size=48, bs=128).normalize(imagenet_stats)

data.show_batch(rows=3, figsize=(8,8))

"""Just to remind you - **0 indicates `no IDC` (no breast cancer) while 1 indicates `IDC`  (breast cancer)**."""

# Training and validation set splits
data.label_list

from collections import Counter

# Training set
train_counts = Counter(data.train_ds.y)
train_counts.most_common()

# Validation set
valid_counts = Counter(data.valid_ds.y)
valid_counts.most_common()

# Initializing the custom class weights and pop it to the GPU
from torch import nn

weights = [0.4, 1]
class_weights=torch.FloatTensor(weights).cuda()

# Begin the training
learn = cnn_learner(data, models.resnet50, metrics=[accuracy]).to_fp16()
learn.loss_func = nn.CrossEntropyLoss(weight=class_weights)
learn.fit_one_cycle(5);
learn.recorder.plot_losses()

# Saving the model
learn.save('stage-1-rn50')

# Model's final validation loss and accuracy
learn.validate()

"""`tensor(0.8685)` denotes an accuracy score of **86.85%**."""

# Model's final training loss and accuracy
learn.validate(learn.data.train_dl)

# Looking at model's results
learn.show_results(rows=3)

interp = ClassificationInterpretation.from_learner(learn)

losses,idxs = interp.top_losses()

len(data.valid_ds)==len(losses)==len(idxs)

interp.plot_top_losses(9, figsize=(12,10), heatmap=False)

interp.plot_confusion_matrix()

from sklearn.metrics import classification_report

def return_classification_report(learn):

    ground_truth = []
    pred_labels = []

    for i in range(len(learn.data.valid_ds)):
        temp_pred = str(learn.predict(learn.data.valid_ds[i][0])[0])
        temp_truth = str(learn.data.valid_ds[i]).split('), ', 1)[1].replace('Category ', '').replace(')', '')
        pred_labels.append(temp_pred)
        ground_truth.append(temp_truth)

    assert len(pred_labels) == len(ground_truth)

    return classification_report(ground_truth, pred_labels, target_names=data.classes)

print(return_classification_report(learn))

learn.lr_find();
learn.recorder.plot()

learn.unfreeze()
learn.fit_one_cycle(2, max_lr=slice(1e-04, 1e-05))

# Save model
learn.save('stage-2-more-rn50')

# Looking at the classification report
print(return_classification_report(learn))

learn.summary()

# Export the model in pickle format
learn.export('breast-cancer-rn50.pkl')